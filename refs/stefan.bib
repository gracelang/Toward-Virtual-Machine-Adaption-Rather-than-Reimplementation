@inproceedings{Marr2015_tracingVpartial,
    Xabstract    = {Tracing and partial evaluation have been proposed as meta-compilation techniques for interpreters to make just-in-time compilation language-independent. They promise that programs executing on simple interpreters can reach performance of the same order of magnitude as if they would be executed on state-of-the-art virtual machines with highly optimizing just-in-time compilers built for a specific language. Tracing and partial evaluation approach this meta-compilation from two ends of a spectrum, resulting in different sets of tradeoffs. This study investigates both approaches in the context of self-optimizing interpreters, a technique for building fast abstract-syntax-tree interpreters. Based on RPython for tracing and Truffle for partial evaluation, we assess the two approaches by comparing the impact of various optimizations on the performance of an interpreter for SOM, an object-oriented dynamically-typed language. The goal is to determine whether either approach yields clear performance or engineering benefits. We find that tracing and partial evaluation both reach roughly the same level of performance. SOM based on meta-tracing is on average 3x slower than Java, while SOM based on partial evaluation is on average 2.3x slower than Java. With respect to the engineering, tracing has however significant benefits, because it requires language implementers to apply fewer optimizations to reach the same level of performance.},
    author       = {Marr, Stefan and Ducasse, Stéphane},
    Xbooktitle   = {Proceedings of the 2015 ACM International Conference on Object Oriented Programming Systems Languages \& Applications},
    Xdoi         = {10.1145/2660193.2660194},
    Xisbn        = {978-1-4503-2585-1},
    Xkeywords    = {Compiler Interpreter JITCompilation MeMyPublication MetaTracing Optimization PartialEvaluation RPython SelfOptimizing Tracing Truffle myown},
    Xnumpagesq   = {19},
    Xpages       = {821--839},
    Xpdf         = {http://stefan-marr.de/downloads/oopsla15-marr-ducasse-meta-tracing-vs-partial-evaluation.pdf},
    Xpublisher   = {ACM},
    series       = {OOPSLA},
    title        = {Tracing vs. Partial Evaluation: Comparing Meta-Compilation Approaches for Self-Optimizing Interpreters},
    year         = 2015
}

@presentation{Marr2015_eventloop,
    Xabstract     = {Communicating Event-Loop Languages similar to E and AmbientTalk are recently gaining more traction as a subset of actor languages. With the rise of JavaScript, E’s notion of vats and non-blocking communication based on promises entered the mainstream. For implementations, the combination of dynamic typing, asynchronous message sending, and promise resolution pose new optimization challenges. This paper discusses these challenges and presents initial experiments for a Newspeak implementation based on the Truffle framework. Our implementation is on average 1.65x slower than Java on a set of 14 benchmarks. Initial optimizations improve the performance of asynchronous messages and reduce the cost of encapsulation on microbenchmarks by about 2x. Parallel actor benchmarks further show that the system scales based on the workload characteristics. Thus, we conclude that Truffle is a promising platform also for communicating event-loop languages.},
    Xadded-at     = {2015-09-25T10:47:48.000+0200},
    author        = {Marr, Stefan and Mössenböck, Hanspeter},
    Xbiburl       = {http://www.bibsonomy.org/bibtex/29f9881cc5d059f4916d4805e780b5e00/gron},
    Xbooktitle    = {AGERE},
    Xday          = 26,
    Xinterhash    = {0a0937a8e45344c88cbe6fb1ad8c42fa},
    Xintrahash    = {9f9881cc5d059f4916d4805e780b5e00},
    Xkeywords     = {Actors Caching CommunicatingEventLoops Compiler Concurrency MeMyPublication Message Optimization PIC Sending Truffle myown},
    Xlocation     = {Pittsburgh, PA, USA},
    Xmonth        = {October},
    Xpdf          = {http://stefan-marr.de/downloads/agere15-agere-marr-moessenboeck-optimizing-communicating-event-loop-languages-with-truffle.pdf},
    Xseries       = {AGERE},
    Xtimestamp    = {2015-09-25T11:39:02.000+0200},
    title         = {Optimizing Communicating Event-Loop Languages with Truffle, {AGERE}},
    Xtype         = {Work-in-Progress-Paper},
    Xurl          = {http://stefan-marr.de/papers/agere-marr-moessenboeck-optimizing-communicating-event-loop-languages-with-truffle/},
    year          = 2015
}

@inproceedings{Marr2016,
    Xabstract    = {Comparing the performance of programming languages is difficult because they differ in many aspects including preferred programming abstractions, available frameworks, and their runtime systems. Nonetheless, the question about relative performance comes up repeatedly in the research community, industry, and wider audience of enthusiasts. This paper presents 14 benchmarks and a novel methodology to assess the compiler effectiveness across language implementations. Using a set of common language abstractions, the benchmarks are implemented in Java, JavaScript, Ruby, Crystal, Newspeak, and Smalltalk. We show that the benchmarks exhibit a wide range of characteristics using language-agnostic metrics. Using four different languages on top of the same compiler, we show that the benchmarks perform similarly and therefore allow for a comparison of compiler effectiveness across languages. Based on anecdotes, we argue that these benchmarks help language implementers to identify performance bugs and optimization potential by comparing to other language implementations.},
    author       = {Marr, Stefan and Daloze, Benoit and Mössenböck, Hanspeter},
    Xbooktitle   = {Proceedings of the 12th Symposium on Dynamic Languages},
    Xdoi         = {10.1145/2989225.2989232},
    Xisbn        = {978-1-4503-4445-6},
    Xkeywords    = {Benchmark Compiler Crystal Graal Java JavaScript MeMyPublication Metrics Newspeak NodeJS Performance Ruby Smalltalk Truffle myown},
    location     = {Amsterdam, Netherlands},
    Xnumpages    = {12},
    Xpages       = {120--131},
    Xpdf         = {http://stefan-marr.de/downloads/dls16-marr-et-al-cross-language-compiler-benchmarking-are-we-fast-yet.pdf},
    Xpublisher   = {ACM},
    series       = {DLS},
    title        = {{Cross-Language Compiler Benchmarking---Are We Fast Yet?}},
    year         = 2016
}

